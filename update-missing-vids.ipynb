{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6416f5-941c-4c21-8731-a49cce1a65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import ffmpeg\n",
    "import moviepy.editor as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import io\n",
    "import PIL\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "import pickle\n",
    "import base64\n",
    "from tqdm.notebook import tqdm\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision\n",
    "from PIL import Image\n",
    "\n",
    "os.chdir(\"/nfs/sloanlab003/projects/arc_proj/story/data/sb_ad_links\")\n",
    "LINK_DIR = \"/nfs/sloanlab003/projects/arc_proj/story/data/sb_ad_links\"\n",
    "PARENT_DIR = \"/nfs/sloanlab003/projects/arc_proj/story/data/sb_ad_vids\"\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506469fd-fb9a-46d8-9f12-2bd91b8db0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import videointelligence_v1 as videointelligence\n",
    "from google.cloud import vision\n",
    "\n",
    "os.chdir(\"/nfs/sloanlab003/projects/arc_proj/story/code/nw/google-cloud-sdk\")\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"/nfs/sloanlab003/projects/arc_proj/story/code/nw/ad-story-arc-b60c485322b4.json\"\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bf7fc-d27e-4d4a-b163-bf603ea621bb",
   "metadata": {},
   "source": [
    "# getting faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5174ec-1be4-483c-91d1-f157231b414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_person(local_file_path):\n",
    "    \"\"\"Detects people in a video from a local file.\"\"\"\n",
    "    from google.oauth2 import service_account\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file(\"/nfs/sloanlab003/projects/arc_proj/story/code/nw/ad-story-arc-b60c485322b4.json\")\n",
    "    \n",
    "    client = videointelligence.VideoIntelligenceServiceClient(credentials=credentials)\n",
    "\n",
    "    with io.open(local_file_path, \"rb\") as f:\n",
    "        input_content = f.read()\n",
    "\n",
    "    # Configure the request\n",
    "    config = videointelligence.FaceDetectionConfig(\n",
    "        include_bounding_boxes=True, include_attributes=True\n",
    "    )\n",
    "    context = videointelligence.VideoContext(face_detection_config=config)\n",
    "\n",
    "    # Start the asynchronous request\n",
    "    operation = client.annotate_video(\n",
    "        request={\n",
    "            \"features\": [videointelligence.Feature.FACE_DETECTION],\n",
    "            \"input_content\": input_content,\n",
    "            \"video_context\": context,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"\\nProcessing video for face detection annotations.\")\n",
    "    result = operation.result(timeout=300)\n",
    "\n",
    "    print(\"\\nFinished processing.\\n\")\n",
    "\n",
    "    # Retrieve the first result, because a single video was processed.\n",
    "    annotation_result = result.annotation_results[0]\n",
    "    \n",
    "    return_list = []\n",
    "\n",
    "    for annotation in annotation_result.face_detection_annotations:\n",
    "        face_info = []\n",
    "        \n",
    "        # print(\"Face detected:\")\n",
    "        for track in annotation.tracks:\n",
    "\n",
    "            timestamped_object = track.timestamped_objects[0]\n",
    "            box = timestamped_object.normalized_bounding_box\n",
    "            \n",
    "            \n",
    "            face_info.append({\"box\": (box.left, box.top, box.right, box.bottom)})\n",
    "            face_info.append({\"start_time\": track.segment.start_time_offset.seconds + track.segment.start_time_offset.microseconds / 1e6})\n",
    "            face_info.append({\"end_time\": track.segment.end_time_offset.seconds + track.segment.end_time_offset.microseconds / 1e6})\n",
    "\n",
    "\n",
    "\n",
    "            return_list.append(face_info)\n",
    "    # print('here', return_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aff8da3-a0e3-4c8f-8dbe-161113719ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_from_video(ID, bounding_box, timestamp):\n",
    "    os.chdir(f'{PARENT_DIR}/{ID}')\n",
    "    filename = ID + '.mp4'\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(filename)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "\n",
    "    while success:\n",
    "        success,frame = vidcap.read()\n",
    "\n",
    "        count+=1\n",
    "        if count/fps >= timestamp:\n",
    "            # print('frame #', count, 'time', count/fps)\n",
    "            imageRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            im = Image.fromarray(imageRGB)\n",
    "            roi = crop_normalized(bounding_box, im)\n",
    "            \n",
    "            vidcap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return roi\n",
    "            break\n",
    "            \n",
    "    vidcap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f533a14-7242-413e-b167-d8ca36a03a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_normalized(bounding_box, image):\n",
    "    left, top, right, bottom = bounding_box[0], bounding_box[1], bounding_box[2], bounding_box[3]\n",
    "    number_of_rows, number_of_columns = image.height, image.width\n",
    "    \n",
    "    top_unormalized = round(top * number_of_rows)\n",
    "    left_unormalized = round(left * number_of_columns)\n",
    "    bottom_unormalized = round(bottom * number_of_rows)\n",
    "    right_unormalized = round(right * number_of_columns)\n",
    "    \n",
    "    return image.crop((left_unormalized, top_unormalized, right_unormalized, bottom_unormalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc56f12-9e76-40bb-92f4-f35e45e9441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3583\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3584\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3585\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3586\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3587\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3588\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3589\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3590\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3591\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3592\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3593\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3594\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3595\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3596\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3597\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3598\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3599\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3600\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3601\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3602\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3603\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3604\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3605\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3606\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3607\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3608\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3609\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3610\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3611\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3612\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3613\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3614\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3615\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3616\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3617\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3618\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3619\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3620\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3621\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3622\n",
      "\n",
      "Processing video for face detection annotations.\n",
      "\n",
      "Finished processing.\n",
      "\n",
      "done with sb_2014_3623\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# run videos through video intelligence API\n",
    "os.chdir(LINK_DIR)\n",
    "df = pd.read_csv(\"nw_2014_included.csv\")\n",
    "df_working = pd.read_csv(\"urop-relabeled.csv\")\n",
    "\n",
    "num_faces_save = 10\n",
    "df2 = df.copy()\n",
    "list_face = list(df[\"faces detected\"])\n",
    "\n",
    "for i in range(3578, df.shape[0]):\n",
    "    \n",
    "    # if pd.isnull(df_working[\"working_links_to_vid\"][i]): \n",
    "    #     continue\n",
    "    # if df_working[\"working_links_to_vid\"][i] == 'no vid found':\n",
    "    #     continue\n",
    "    if df['needs_processing'][i] == 0:\n",
    "        continue\n",
    "    \n",
    "    ID = df[\"id\"][i]\n",
    "    os.chdir(f'{PARENT_DIR}/{ID}')\n",
    "    \n",
    "    # try:\n",
    "    result = detect_person(ID+\".mp4\")\n",
    "    segment_length = {}\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f\"{PARENT_DIR}/{ID}/google_video_face_samples\")\n",
    "    except:\n",
    "        os.chdir(f\"{PARENT_DIR}/{ID}/google_video_face_samples\")\n",
    "\n",
    "    for j, face in enumerate(result[::-1]):\n",
    "        bb = face[0]['box']\n",
    "        start_time = face[1]['start_time']\n",
    "        end_time = face[2]['end_time']\n",
    "        segment_length[end_time - start_time] = (bb, start_time)\n",
    "\n",
    "    num_faces = len(segment_length.keys())\n",
    "    top_faces = sorted(segment_length.keys(), reverse=True)[:num_faces_save]\n",
    "\n",
    "    # df2['faces detected'][i] = num_faces\n",
    "    list_face[i] = num_faces\n",
    "\n",
    "    # if i % 500 == 0 and i != 0:\n",
    "    #     os.chdir(LINK_DIR)\n",
    "    #     df2.to_csv(f'temp_{i-500}-{i}.csv', index=False)\n",
    "\n",
    "\n",
    "    for j, segment in enumerate(top_faces):\n",
    "        (bb, start_time) = segment_length[segment]\n",
    "        roi = crop_from_video(ID, bb, start_time)\n",
    "        roi.save(f\"{PARENT_DIR}/{ID}/google_video_face_samples/{str(j).zfill(3)}_{str(round(start_time, 2)).zfill(5)}.jpg\")\n",
    "\n",
    "    print('done with', ID)\n",
    "    # except:\n",
    "    #     didnt_work.append(ID)\n",
    "    #     print(ID, \"didn't work\")\n",
    "        \n",
    "df2[\"faces detected\"] = list_face\n",
    "os.chdir(LINK_DIR)\n",
    "df2.to_csv('nw_2014_included_v2.csv', index=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cadffc-1f5b-4535-a7d2-1cf56c484bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nw_jan_fixed_visual.csv\")\n",
    "df_working = pd.read_csv(\"urop-relabeled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
